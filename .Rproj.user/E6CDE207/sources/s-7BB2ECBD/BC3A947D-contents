---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# focus: Feature selectiOn and Clustering Using Stability

<!-- badges: start -->
<!-- badges: end -->

Implementation of stability-enhanced models 
for variable selection in regression, graphical modelling and clustering. 
These methods are based on resampling approaches to compute selection proportions. 
Calibration of the models is done via maximisation of a stability score 
measuring how unlikely it is that the selection procedure is uniform.

## Installation

<!-- You can install the released version of focus from [CRAN](https://CRAN.R-project.org) with: -->

<!-- ``` r -->
<!-- install.packages("focus") -->
<!-- ``` -->

The development version can be installed from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("barbarabodinier/focus")
```

## Variable selection

### Data simulation

A dataset with n=100 observations for p=50 potential predictors and a continuous outcome is simulated:

```{r}
library(focus)

# Data simulation
set.seed(1)
simul=SimulateRegression(n=100, pk=50)

# Potential predictors
X=simul$X 
print(dim(X))

# Continuous outcome
Y=simul$Y 
print(dim(Y))
```


### Stability selection

Stability selection in a regression framework is implemented in the function `VariableSelection()`. The predictor and outcome datasets are provided as input:

```{r results="hide"}
stab=VariableSelection(xdata=X, ydata=Y)
```

Stability selection models are run for multiple pairs of parameters λ (controlling the sparsity of the underlying algorithm) and π (threshold in selection proportions). By default, stability selection is run in applied to LASSO regression, as implemented in `glmnet`. The grids of parameter values used in the run can be extracted using: 

```{r}
# First few penalty parameters
print(head(stab$Lambda)) 

# Grid of thresholds in selection proportion
print(stab$params$pi_list)

# Number of model pairs (i.e. number of visited stability selection models)
print(nrow(stab$Lambda)*length(stab$params$pi_list))
```


### Calibration 

The two parameters are jointly calibrated by maximising the stability score, measuring how unlikely it is that features are uniformly selected:

```{r fig.height=7, fig.width=9, out.width="80%", fig.align="center"}
CalibrationPlot(stab)
```

Visited penalty parameters λ are represented on the x-axis. The corresponding average number of selected features by the underlying algorithm (here, LASSO models) are reported on the z-axis and denoted by q. The different thresholds in selection proportions π are represented on the y-axis. The stability score obtained for different pairs of parameters (λ, π) are colour-coded and ranging from 0 to 1,200 on this example. 


### Outputs

The calibrated set of stably selected variables is obtained from:

```{r}
stably_selected=SelectedVariables(stab)
print(stably_selected)
print(table(stably_selected))
```

In this example, 11 variables are stably selected. 

Additionally, selection proportions of the calibrated model can be extracted:

```{r}
selprop=SelectionProportions(stab)
print(selprop)
```

Selection proportions can be used to rank the variables by relevance in association with the outcome:

```{r fig.height=7, fig.width=12, out.width="100%", fig.align="center"}
selprop_ranked=sort(selprop, decreasing=TRUE)
plot(selprop_ranked, type="h", lwd=3, las=1, cex.lab=1.3, bty="n", ylim=c(0,1),
     col=ifelse(selprop_ranked>=Argmax(stab)[2],yes="red",no="grey"),
     xaxt="n", xlab="", ylab="Selection proportions")
abline(h=Argmax(stab)[2], lty=2, col="darkred")
axis(side=1, at=1:length(selprop_ranked), labels=names(selprop_ranked), las=2)
```



## Graphical modelling

### Data simulation

A dataset with n=100 observations of p=20 nodes with an underlying graph structure is simulated:

```{r}
# Data simulation
set.seed(1)
simul=SimulateGraphical(n=100, pk=20, topology="scale-free")

# Variables are nodes
X=simul$data
print(dim(X))
```

### Stability selection

Stability selection for graphical modelling is implemented in `GraphicalModel()`. It takes the data as input:

```{r results="hide"}
stab=GraphicalModel(xdata=X)
```


### Calibration 

As for variable selection, the stability selection graphical model is controlled by two parameters controlling the sparsity of the underlying algorithm and threshold in selection proportion. These parameters are jointly calibrated by maximising the stability score:

```{r fig.height=7, fig.width=9, out.width="80%", fig.align="center"}
CalibrationPlot(stab)
```


### Outputs

The adjacency matrix of the calibrated stability selection graphical model is obtained with:

```{r}
myadjacency=Adjacency(stab)
print(myadjacency)
```

For visualisation, it can be converted into an igraph object:

```{r fig.height=10, fig.width=10, out.width="100%", fig.align="center"}
mygraph=Graph(myadjacency)
plot(mygraph)
```

