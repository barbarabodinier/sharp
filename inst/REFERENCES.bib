@misc{ourstabilityselection,
      title={Automated calibration for stability selection in penalised regression and graphical models: a multi-OMICs network application exploring the molecular response to tobacco smoking}, 
      author={Barbara Bodinier and Sarah Filippi and Therese Haugdahl Nost and Julien Chiquet and Marc Chadeau-Hyam},
      year={2021},
      eprint={2106.02521},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url = {https://arxiv.org/abs/2106.02521}
}


@article{stabilityselectionMB,
author = {Meinshausen, Nicolai and Bühlmann, Peter},
title = {Stability selection},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {72},
number = {4},
pages = {417-473},
keywords = {High dimensional data, Resampling, Stability selection, Structure estimation},
doi = {10.1111/j.1467-9868.2010.00740.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2010.00740.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2010.00740.x},
abstract = {Summary.  Estimation of structure, such as in variable selection, graphical modelling or cluster analysis, is notoriously difficult, especially for high dimensional data. We introduce stability selection. It is based on subsampling in combination with (high dimensional) selection algorithms. As such, the method is extremely general and has a very wide range of applicability. Stability selection provides finite sample control for some error rates of false discoveries and hence a transparent principle to choose a proper amount of regularization for structure estimation. Variable selection and structure estimation improve markedly for a range of selection methods if stability selection is applied. We prove for the randomized lasso that stability selection will be variable selection consistent even if the necessary conditions for consistency of the original lasso method are violated. We demonstrate stability selection for variable selection and Gaussian graphical modelling, using real and simulated data.},
year = {2010}
}


@article{stabilityselectionSS,
author = {Shah, Rajen D. and Samworth, Richard J.},
title = {Variable selection with error control: another look at stability selection},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
volume = {75},
number = {1},
pages = {55-80},
keywords = {Complementary pairs stability selection, r-concavity, Subagging, Subsampling, Variable selection},
doi = {10.1111/j.1467-9868.2011.01034.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2011.01034.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2011.01034.x},
abstract = {Summary.  Stability selection was recently introduced by Meinshausen and Bühlmann as a very general technique designed to improve the performance of a variable selection algorithm. It is based on aggregating the results of applying a selection procedure to subsamples of the data. We introduce a variant, called complementary pairs stability selection, and derive bounds both on the expected number of variables included by complementary pairs stability selection that have low selection probability under the original procedure, and on the expected number of high selection probability variables that are excluded. These results require no (e.g. exchangeability) assumptions on the underlying model or on the quality of the original selection procedure. Under reasonable shape restrictions, the bounds can be further tightened, yielding improved error control, and therefore increasing the applicability of the methodology.},
year = {2013}
}


@article{sparsePCA,
author = {Hui Zou and Trevor Hastie and Robert Tibshirani},
title = {Sparse Principal Component Analysis},
journal = {Journal of Computational and Graphical Statistics},
volume = {15},
number = {2},
pages = {265-286},
year  = {2006},
publisher = {Taylor & Francis},
doi = {10.1198/106186006X113430},
URL = { 
        https://doi.org/10.1198/106186006X113430   
},
eprint = { 
        https://doi.org/10.1198/106186006X113430   
}
}


@article{sparsePLS,
   author = {KA, Lê Cao and Rossouw, D. and Robert-Granié, C. and Besse, P.},
   title = {A sparse PLS for variable selection when integrating omics data},
   journal = {Stat Appl Genet Mol Biol},
   volume = {7},
   number = {1},
   pages = {Article 35},
   ISSN = {1544-6115},
   DOI = {10.2202/1544-6115.1390},
   year = {2008},
   type = {Journal Article}
}



@article{sparsegroupPLS,
   author = {Liquet, B. and de Micheaux, P. L. and Hejblum, B. P. and Thiébaut, R.},
   title = {Group and sparse group partial least square approaches applied in genomics context},
   journal = {Bioinformatics},
   volume = {32},
   number = {1},
   pages = {35-42},
   ISSN = {1367-4803},
   DOI = {10.1093/bioinformatics/btv535},
   year = {2016},
   type = {Journal Article}
}
