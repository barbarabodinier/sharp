% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bi_selection.R
\name{BiSelection}
\alias{BiSelection}
\title{Variable selection for predictors and outcomes}
\usage{
BiSelection(
  xdata,
  ydata = NULL,
  group_x = NULL,
  group_y = NULL,
  LambdaX = NULL,
  LambdaY = NULL,
  AlphaX = NULL,
  AlphaY = NULL,
  ncomp = 1,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  family = "gaussian",
  implementation = SparsePLS,
  resampling = "subsampling",
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{xdata}{matrix of predictors with observations as rows and variables as
columns.}

\item{ydata}{optional vector or matrix of outcome(s). If \code{family} is set
to \code{"binomial"} or \code{"multinomial"}, \code{ydata} can be a vector
with character/numeric values, or a factor.}

\item{group_x}{vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used with
\code{implementation="SparseGroupPLS"}.}

\item{group_y}{optional vector encoding the grouping structure among
outcomes. This argument indicates the number of variables in each group.
Only used with \code{implementation="SparseGroupPLS"}.}

\item{LambdaX}{matrix of parameters controlling the number of selected
variables (sparse PLS) or groups (sparse group PLS) in X.}

\item{LambdaY}{matrix of parameters controlling the number of selected
variables (sparse PLS) or groups (sparse group PLS) in Y. Only used with
\code{family="gaussian"}.}

\item{AlphaX}{matrix of parameters controlling the level of sparsity within
groups (sparse group PLS) in X. Only used with
\code{implementation="SparseGroupPLS"}.}

\item{AlphaY}{matrix of parameters controlling the level of sparsity within
groups (sparse group PLS) in X. Only used with
\code{implementation="SparseGroupPLS"} and \code{family="gaussian"}.}

\item{ncomp}{number of components.}

\item{pi_list}{vector of thresholds in selection proportions. If
\code{n_cat=3}, these values must be \code{>0.5} and \code{<1}. If
\code{n_cat=2}, these values must be \code{>0} and \code{<1}.}

\item{K}{number of resampling iterations.}

\item{tau}{subsample size. Only used with \code{resampling="subsampling"}.}

\item{seed}{value of the seed.}

\item{n_cat}{number of categories used to compute the stability score.
Possible values are 2 or 3.}

\item{family}{type of regression model. If
\code{implementation=PenalisedRegression}, this argument is defined as in
\code{\link[glmnet]{glmnet}}. Possible values include \code{"gaussian"}
(linear regression), \code{"binomial"} (logistic regression),
\code{"multinomial"} (multinomial regression), and \code{"cox"} (survival
analysis).}

\item{implementation}{function to use for variable selection. By default,
\code{PenalisedRegression}, based on \code{\link[glmnet]{glmnet}}, is used
for regularised regression. Other possible functions are: \code{SparsePLS},
\code{GroupPLS} and \code{SparseGroupPLS}. Alternatively, a function with
arguments \code{xdata}, \code{ydata}, \code{Lambda}, \code{family} and
\code{...}, and returning a list of two matrices named \code{selected} and
\code{beta_full} of the correct dimensions can be used.}

\item{resampling}{resampling approach. Possible values are:
\code{"subsampling"} for sampling without replacement of a proportion
\code{tau} of the observations, or \code{"bootstrap"} for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named \code{data} and
\code{tau} and return IDs of observations to be included in the resampled
dataset (see example in \code{\link{Resample}}).}

\item{PFER_method}{method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). With
\code{PFER_method="MB"}, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. With \code{PFER_method="SS"}, the method proposed by Shah
and Samworth (2013) under the assumption of unimodality is used.}

\item{PFER_thr}{threshold in PFER for constrained calibration by error
control. With \code{PFER_thr=Inf} and \code{FDP_thr=Inf}, unconstrained
calibration is used.}

\item{FDP_thr}{threshold in the expected proportion of falsely selected
features (or False Discovery Proportion, FDP) for constrained calibration
by error control. With \code{PFER_thr=Inf} and \code{FDP_thr=Inf},
unconstrained calibration is used.}

\item{n_cores}{number of cores to use for parallel computing. Only available
on Unix systems.}

\item{output_data}{logical indicating if the input datasets \code{xdata} and
\code{ydata} should be included in the output.}

\item{verbose}{logical indicating if a loading bar and messages should be
printed.}

\item{...}{additional parameters passed to the functions provided in
\code{implementation} or \code{resampling}.}
}
\value{
A list with: \item{summary}{a matrix of the best stability scores and
  corresponding parameters controlling the level of sparsity in the
  underlying algorithm for different numbers of components. Possible columns
  include: \code{comp} (component ID), \code{nx} (number of predictors to
  include, parameter of the underlying algorithm), \code{alphax} (sparsity
  within the predictor groups, parameter of the underlying algorithm),
  \code{pix} (threshold in selection proportion for predictors), \code{ny}
  (number of outcomes to include, parameter of the underlying algorithm),
  \code{alphay} (sparsity within the outcome groups, parameter of the
  underlying algorithm), \code{piy} (threshold in selection proportion for
  outcomes), \code{S} (stability score). Columns that are not relevant to the
  model are not reported. For example, \code{alpha_x} and \code{alpha_y} are
  not used in sparse PLS models.} \item{summary_full}{a matrix of the
  stability scores for the visited combinations of parameters. Values are
  reported for the calibrated threshold(s) in selection proportions.}
  \item{selectedX}{a binary matrix encoding stably selected predictors.}
  \item{selpropX}{a matrix with the selection proportions of predictors.}
  \item{selectedY}{a binary matrix encoding stably selected outcomes.}
  \item{selpropY}{a matrix with the selection proportions of outcomes.}
  \item{selectedX_full}{a binary matrix encoding stably selected predictors.}
  \item{selpropX_full}{a binary matrix encoding stably selected predictors.}
  \item{selectedY_full}{a binary matrix encoding stably selected outcomes.}
  \item{selpropY_full}{a binary matrix encoding stably selected outcomes.}
  \item{method}{a list with \code{type="bi_selection"},
  \code{implementation}, \code{family}, \code{resampling} and
  \code{PFER_method} values used for the run.} \item{params}{a list of input
  values used for the run. The datasets \code{xdata} and \code{ydata} are
  also included if \code{output_data=TRUE}.} The rows of \code{selectedX},
  \code{selectedY}, \code{selpropX} and \code{selpropY} correspond to the
  different combinations of parameters listed in \code{summary}. The rows of
  \code{selectedX_full}, \code{selectedY_full}, \code{selpropX_full} and
  \code{selpropY_full} correspond to the different combinations of parameters
  listed in \code{summary_full}.
}
\description{
Runs stability selection regression models with different combinations of
parameters controlling the sparsity in PLS models and thresholds in selection
proportions. These parameters are jointly calibrated by maximising the
stability score of the model (possibly under a constraint on the expected
number of falsely stably selected features).
}
\examples{
\dontshow{

# Data simulation
K <- 5
pk <- 15
set.seed(1)
simul <- SimulateRegression(n = 50, pk = pk, family = "gaussian")
ydata <- cbind(simul$Y, matrix(rnorm(50 * 3), ncol = 3))
colnames(ydata) <- paste0("outcome", 1:4)
x <- simul$X
y <- ydata

# sPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y,
  family = "gaussian", K = K, ncomp = 2,
  LambdaX = 1:2,
  LambdaY = 1:2,
  implementation = SparsePLS
)

# sPCA: sparsity on X
stab <- BiSelection(
  xdata = x,
  K = K, ncomp = 2,
  LambdaX = 1:2,
  implementation = SparsePCA
)
}

\dontrun{

# Data simulation (continuous outcomes)
pk <- 15
set.seed(1)
simul <- SimulateRegression(n = 50, pk = pk, family = "gaussian")
ydata <- cbind(simul$Y, matrix(rnorm(50 * 3), ncol = 3))
colnames(ydata) <- paste0("outcome", 1:4)
x <- simul$X
y <- ydata

# sPCA: sparsity on X (unsupervised)
stab <- BiSelection(
  xdata = x,
  K = K, ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  implementation = SparsePCA
)

# sPLS: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = y,
  family = "gaussian", ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  implementation = SparsePLS
)

# sPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y,
  family = "gaussian", ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  LambdaY = 1:(ncol(y) - 1),
  implementation = SparsePLS
)

# sgPLS: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = y,
  group_x = c(2, 10, 8),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2, AlphaX = seq(0.1, 0.9, by = 0.1),
  implementation = SparseGroupPLS
)

# sgPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y,
  group_x = c(2, 10, 8), group_y = c(1, 3),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2, AlphaX = seq(0.1, 0.9, by = 0.1),
  LambdaY = 1:2, AlphaY = seq(0.1, 0.9, by = 0.1),
  implementation = SparseGroupPLS
)

# gPLS: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = y,
  group_x = c(2, 10, 8),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2,
  implementation = GroupPLS
)

# gPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y,
  group_x = c(2, 10, 8), group_y = c(1, 3),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2, LambdaY = 1:2,
  implementation = GroupPLS
)

# Data simulation (categorical outcomes)
set.seed(1)
simul <- SimulateRegression(n = 200, pk = 20, family = "binomial")
x <- simul$X
y <- cbind(simul$Y, matrix(sample(c(0, 1), size = 200 * 3, replace = TRUE), ncol = 3))
y <- apply(y, 1, sum)

# sPLS-DA: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = cbind(y),
  family = "binomial", ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  implementation = SparsePLS
)

# sgPLS-DA: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = cbind(y),
  group_x = c(2, 10, 8), K = 10,
  family = "binomial", ncomp = 3,
  LambdaX = 1:2, AlphaX = seq(0.1, 0.9, by = 0.1),
  implementation = SparseGroupPLS
)

# gPLS-DA: sparsity on Y
stab <- BiSelection(
  xdata = x, ydata = cbind(y),
  group_x = c(2, 10, 8),
  family = "binomial", ncomp = 3,
  LambdaX = 1:2,
  implementation = GroupPLS
)
}
}
\references{
\insertRef{ourstabilityselection}{focus}

  \insertRef{stabilityselectionMB}{focus}

  \insertRef{stabilityselectionSS}{focus}
}
\seealso{
\code{\link{SparsePLS}}, \code{\link{GroupPLS}},
  \code{\link{SparseGroupPLS}}, \code{\link{Resample}},
  \code{\link{StabilityScore}}

Other stability selection functions: 
\code{\link{Clustering}()},
\code{\link{GraphicalModel}()},
\code{\link{VariableSelection}()}
}
\concept{stability selection functions}
