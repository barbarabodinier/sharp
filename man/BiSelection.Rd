% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bi_selection.R
\name{BiSelection}
\alias{BiSelection}
\title{Stability selection of both predictors and outcomes}
\usage{
BiSelection(
  xdata,
  ydata = NULL,
  group_x = NULL,
  group_y = NULL,
  LambdaX = NULL,
  LambdaY = NULL,
  AlphaX = NULL,
  AlphaY = NULL,
  ncomp = 1,
  scale = TRUE,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  family = "gaussian",
  implementation = SparsePLS,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{xdata}{matrix of predictors with observations as rows and variables as
columns.}

\item{ydata}{optional vector or matrix of outcome(s). If \code{family} is set
to \code{"binomial"} or \code{"multinomial"}, \code{ydata} can be a vector
with character/numeric values, or a factor.}

\item{group_x}{vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used with
\code{implementation=SparseGroupPLS} or \code{implementation=GroupPLS}.}

\item{group_y}{optional vector encoding the grouping structure among
outcomes. This argument indicates the number of variables in each group.
Only used with \code{implementation=SparseGroupPLS}.}

\item{LambdaX}{matrix of parameters controlling the number of selected
variables (sparse PLS) or groups (sparse group PLS) in X.}

\item{LambdaY}{matrix of parameters controlling the number of selected
variables (sparse PLS) or groups (sparse group PLS) in Y. Only used with
\code{family="gaussian"}.}

\item{AlphaX}{matrix of parameters controlling the level of sparsity within
groups (sparse group PLS) in X. Only used with
\code{implementation=SparseGroupPLS}.}

\item{AlphaY}{matrix of parameters controlling the level of sparsity within
groups (sparse group PLS) in X. Only used with
\code{implementation=SparseGroupPLS} and \code{family="gaussian"}.}

\item{ncomp}{number of components.}

\item{scale}{logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one).}

\item{pi_list}{vector of thresholds in selection proportions. If
\code{n_cat=3}, these values must be \code{>0.5} and \code{<1}. If
\code{n_cat=2}, these values must be \code{>0} and \code{<1}.}

\item{K}{number of resampling iterations.}

\item{tau}{subsample size. Only used with \code{resampling="subsampling"}.}

\item{seed}{value of the seed to ensure reproducibility of the results.}

\item{n_cat}{number of categories used to compute the stability score.
Possible values are 2 or 3.}

\item{family}{type of PLS model. This parameter must be set to
\code{family="gaussian"} for continuous outcomes, or to
\code{family="binomial"} for categorical outcomes. Only used if
\code{ydata} is provided.}

\item{implementation}{function to use for variable selection. By default,
\code{PenalisedRegression}, based on \code{\link[glmnet]{glmnet}}, is used
for regularised regression. Other possible functions are: \code{SparsePLS},
\code{GroupPLS} and \code{SparseGroupPLS}. Alternatively, a function with
arguments \code{xdata}, \code{ydata}, \code{Lambda}, \code{family} and
\code{...}, and returning a list of two matrices named \code{selected} and
\code{beta_full} of the correct dimensions can be used.}

\item{resampling}{resampling approach. Possible values are:
\code{"subsampling"} for sampling without replacement of a proportion
\code{tau} of the observations, or \code{"bootstrap"} for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named \code{data} and
\code{tau} and return IDs of observations to be included in the resampled
dataset (see example in \code{\link{Resample}}).}

\item{cpss}{logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsets. With this method, the data is split
\code{K/2} times (\code{K} models are fitted). If \code{PFER_method="SS"},
complementary pair stability selection is used (\code{cpss} is set to
\code{TRUE}). Argument \code{tau} is ignored if \code{cpss=TRUE}.}

\item{PFER_method}{method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). With
\code{PFER_method="MB"}, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. With \code{PFER_method="SS"}, the method proposed by Shah
and Samworth (2013) under the assumption of unimodality is used.}

\item{PFER_thr}{threshold in PFER for constrained calibration by error
control. With \code{PFER_thr=Inf} and \code{FDP_thr=Inf}, unconstrained
calibration is used.}

\item{FDP_thr}{threshold in the expected proportion of falsely selected
features (or False Discovery Proportion, FDP) for constrained calibration
by error control. With \code{PFER_thr=Inf} and \code{FDP_thr=Inf},
unconstrained calibration is used.}

\item{n_cores}{number of cores to use for parallel computing. Only available
on Unix systems.}

\item{output_data}{logical indicating if the input datasets \code{xdata} and
\code{ydata} should be included in the output.}

\item{verbose}{logical indicating if a loading bar and messages should be
printed.}

\item{...}{additional parameters passed to the functions provided in
\code{implementation} or \code{resampling}.}
}
\value{
A list with: \item{summary}{a matrix of the best stability scores and
  corresponding parameters controlling the level of sparsity in the
  underlying algorithm for different numbers of components. Possible columns
  include: \code{comp} (component ID), \code{nx} (number of predictors to
  include, parameter of the underlying algorithm), \code{alphax} (sparsity
  within the predictor groups, parameter of the underlying algorithm),
  \code{pix} (threshold in selection proportion for predictors), \code{ny}
  (number of outcomes to include, parameter of the underlying algorithm),
  \code{alphay} (sparsity within the outcome groups, parameter of the
  underlying algorithm), \code{piy} (threshold in selection proportion for
  outcomes), \code{S} (stability score). Columns that are not relevant to the
  model are not reported. For example, \code{alpha_x} and \code{alpha_y} are
  not used in sparse PLS models.} \item{summary_full}{a matrix of the
  stability scores for the visited combinations of parameters. Values are
  reported for the calibrated threshold(s) in selection proportions.}
  \item{selectedX}{a binary matrix encoding stably selected predictors.}
  \item{selpropX}{a matrix with the calibrated selection proportions of
  predictors.} \item{selectedY}{a binary matrix encoding stably selected
  outcomes.} \item{selpropY}{a matrix with the calibrated selection
  proportions of outcomes.} \item{selected}{a binary matrix encoding stable
  relationships between predictor and outcome variables.}
  \item{selectedX_full}{a binary matrix encoding stably selected predictors.}
  \item{selpropX_full}{a matrix with the selection proportions of
  predictors.} \item{selectedY_full}{a binary matrix encoding stably selected
  outcomes.} \item{selpropY_full}{a matrix with the selection proportions of
  outcomes.} \item{coefX}{an array of loadings coefficients for the
  predictors (columns) over the fitted components (rows) and across the
  \code{K} resampling iterations (along the third dimension).}
  \item{coefY}{an array of loadings coefficients for the outcomes (columns)
  over the fitted components (rows) and across the \code{K} resampling
  iterations (along the third dimension). Only returned for supervised
  approaches (PLS).} \item{method}{a list with \code{type="bi_selection"},
  \code{implementation}, \code{family}, \code{resampling} and
  \code{PFER_method} values used for the run.} \item{params}{a list of input
  values used for the run. The datasets \code{xdata} and \code{ydata} are
  also included if \code{output_data=TRUE}.} The rows of \code{selectedX},
  \code{selectedY}, \code{selpropX} and \code{selpropY} correspond to the
  different combinations of parameters listed in \code{summary}. The rows of
  \code{selectedX_full}, \code{selectedY_full}, \code{selpropX_full} and
  \code{selpropY_full} correspond to the different combinations of parameters
  listed in \code{summary_full}.
}
\description{
Runs stability selection regression models with different combinations of
parameters controlling the sparsity in PLS/PCA models and thresholds in
selection proportions. These parameters are jointly calibrated by maximising
the stability score of the model (possibly under a constraint on the expected
number of falsely stably selected features).
}
\examples{
\dontshow{

# Data simulation
K <- 5
set.seed(1)
simul <- SimulateRegression(n = 50, pk = c(5, 5, 5), family = "gaussian")

# sPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian", K = K, ncomp = 2,
  LambdaX = 1:2,
  LambdaY = 1:2,
  implementation = SparsePLS
)

# Data simulation
set.seed(1)
simul <- SimulateComponents(n = 50, pk = c(5, 5, 5))

# sPCA: sparsity on X
stab <- BiSelection(
  xdata = simul$data,
  K = K, ncomp = 2,
  LambdaX = 1:2,
  implementation = SparsePCA
)
}

\dontrun{
par(mar = c(12, 5, 1, 1))


## Sparse Principal Component Analysis

# Data simulation
set.seed(1)
simul <- SimulateComponents(pk = c(5, 3, 4))

# sPCA: sparsity on X (unsupervised)
stab <- BiSelection(
  xdata = simul$data,
  ncomp = 3,
  LambdaX = 1:(ncol(simul$data) - 1),
  implementation = SparsePCA
)
print(stab)

# Calibration plot
CalibrationPlot(stab)

# Visualisation of the results
summary(stab)
plot(stab)
SelectedVariables(stab)


## Sparse/Group Partial Least Squares

# Data simulation (continuous outcomes)
set.seed(1)
simul <- SimulateRegression(n = 50, pk = c(5, 5, 5), family = "gaussian")
x <- simul$xdata
y <- simul$ydata

# sPLS: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = y,
  family = "gaussian", ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  implementation = SparsePLS
)
CalibrationPlot(stab)
summary(stab)
plot(stab)

# sPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y,
  family = "gaussian", ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  LambdaY = 1:(ncol(y) - 1),
  implementation = SparsePLS,
  n_cat = 2
)
CalibrationPlot(stab)
summary(stab)
plot(stab)

# sgPLS: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = y, K = 10,
  group_x = c(2, 8, 5),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2, AlphaX = seq(0.1, 0.9, by = 0.1),
  implementation = SparseGroupPLS
)
CalibrationPlot(stab)
summary(stab)

# sgPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y, K = 10,
  group_x = c(2, 8, 5), group_y = c(1, 2),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2, AlphaX = seq(0.1, 0.9, by = 0.2),
  LambdaY = 1:2, AlphaY = seq(0.1, 0.9, by = 0.2),
  implementation = SparseGroupPLS,
  n_cat = 2
)
CalibrationPlot(stab)
CalibrationPlot(stab,
  params = c("nx", "alphax", "ny", "alphay")
)
summary(stab)

# gPLS: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = y,
  group_x = c(2, 8, 5),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2,
  implementation = GroupPLS
)
CalibrationPlot(stab)
summary(stab)

# gPLS: sparsity on both X and Y
stab <- BiSelection(
  xdata = x, ydata = y,
  group_x = c(2, 8, 5), group_y = c(1, 2),
  family = "gaussian", ncomp = 3,
  LambdaX = 1:2, LambdaY = 1:2,
  implementation = GroupPLS
)
CalibrationPlot(stab)
summary(stab)


## Sparse/Group PLS-DA (Discriminant Analysis)

# Data simulation (categorical outcomes)
set.seed(1)
simul <- SimulateRegression(n = 200, pk = c(5, 5, 5), family = "binomial")
x <- simul$xdata
y <- simul$ydata

# sPLS-DA: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = cbind(y),
  family = "binomial", ncomp = 3,
  LambdaX = 1:(ncol(x) - 1),
  implementation = SparsePLS
)
CalibrationPlot(stab)
summary(stab)

# sgPLS-DA: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = cbind(y), K = 10,
  group_x = c(2, 8, 5),
  family = "binomial", ncomp = 3,
  LambdaX = 1:2, AlphaX = seq(0.1, 0.9, by = 0.1),
  implementation = SparseGroupPLS
)
CalibrationPlot(stab)
summary(stab)

# gPLS-DA: sparsity on X
stab <- BiSelection(
  xdata = x, ydata = cbind(y),
  group_x = c(2, 8, 5),
  family = "binomial", ncomp = 3,
  LambdaX = 1:2,
  implementation = GroupPLS
)
CalibrationPlot(stab)
summary(stab)
}
}
\references{
\insertRef{sparsegroupPLS}{focus}

  \insertRef{sparsePLS}{focus}

  \insertRef{sparsePCA}{focus}

  \insertRef{sparsePCASVD}{focus}

  \insertRef{stabilityselectionMB}{focus}

  \insertRef{stabilityselectionSS}{focus}

  \insertRef{ourstabilityselection}{focus}
}
\seealso{
\code{\link{SparsePLS}}, \code{\link{GroupPLS}},
  \code{\link{SparseGroupPLS}}, \code{\link{Resample}},
  \code{\link{StabilityScore}}

Other stability selection functions: 
\code{\link{Clustering}()},
\code{\link{GraphicalModel}()},
\code{\link{VariableSelection}()}
}
\concept{stability selection functions}
