% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/algorithms.R
\name{SelectionAlgo}
\alias{SelectionAlgo}
\title{Variable selection algorithm}
\usage{
SelectionAlgo(x, y, lambda, family, implementation = "glmnet", ...)
}
\arguments{
\item{x}{matrix of predictors with observations as rows and variables as
columns.}

\item{y}{vector or matrix of outcome(s).}

\item{lambda}{matrix of parameters controlling the underlying feature
selection algorithm specified in "implementation". With
implementation="glmnet", these are penalty parameters controlling the
regularised model.}

\item{family}{type of regression model. This argument is defined as in the
\code{\link[glmnet]{glmnet}} function from the glmnet package. Possible values
include "gaussian" (linear regression), "binomial" (logistic regression),
"multinomial" (multinomial regression), and "cox" (survival analysis). This
argument is only used with implementation="glmnet", or with functions using
the family argument in the same way (see example below).}

\item{implementation}{name of the function to use for variable selection.
With implementation="glmnet", the function \code{\link[glmnet]{glmnet}} is called.
Alternatively, this argument can be a character string indicating the name
of a function. The function provided must use arguments called "x", "y",
"lambda" and "family" and return matrices of model coefficients (see
example below).}

\item{...}{additional parameters passed to the function provided in
"implementation".}
}
\value{
A list with: \item{selected}{matrix of binary selection status. Rows
  correspond to different model parameters. Columns correspond to
  predictors.} \item{beta_full}{array of model coefficients. Rows correspond
  to different model parameters. Columns correspond to predictors. Indices
  along the third dimension correspond to outcome variable(s).}
}
\description{
Runs the variable selection algorithm specified in the argument
"implementation" and returns matrices of model coefficients. This function is
not using stability.
}
\examples{
# Data simulation
set.seed(1)
simul <- SimulateRegression(pk = 50)

# Running the LASSO
mylasso <- SelectionAlgo(x = simul$X, y = simul$Y, lambda = c(0.1, 0.2), family = "gaussian")

# Simulation of additional outcomes
set.seed(2)
Y <- cbind(simul$Y, matrix(rnorm(nrow(simul$Y) * 2), ncol = 2))

# Running multivariate Gaussian LASSO
mylasso <- SelectionAlgo(x = simul$X, y = Y, lambda = c(0.1, 0.2), family = "mgaussian")
str(mylasso)
stab <- VariableSelection(xdata = simul$X, ydata = Y, family = "mgaussian")
}
\seealso{
Other underlying algorithm functions: 
\code{\link{GraphicalAlgo}()}
}
\concept{underlying algorithm functions}
