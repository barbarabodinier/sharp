% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clustering.R
\name{Clustering}
\alias{Clustering}
\title{Consensus clustering}
\usage{
Clustering(
  xdata,
  Lambda = NULL,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  implementation = HierarchicalClustering,
  scale = TRUE,
  resampling = "subsampling",
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{xdata}{data matrix with observations as rows and variables as columns.}

\item{Lambda}{matrix of parameters controlling the number of clusters in the
underlying algorithm specified in \code{implementation}. If \code{Lambda}
is not provided, it is set to \code{seq(1, nrow(xdata))}.}

\item{pi_list}{vector of thresholds in selection proportions. If
\code{n_cat=3}, these values must be \code{>0.5} and \code{<1}. If
\code{n_cat=2}, these values must be \code{>0} and \code{<1}.}

\item{K}{number of resampling iterations.}

\item{tau}{subsample size. Only used with \code{resampling="subsampling"}.}

\item{seed}{value of the seed.}

\item{n_cat}{number of categories used to compute the stability score.
Possible values are 2 or 3.}

\item{implementation}{function to use for clustering. Possible functions
include \code{\link{HierarchicalClustering}} (hierarchical clustering),
\code{\link{KMeansClustering}} (k-means), \code{\link{GMMClustering}}
(Gaussian Mixture Models) and \code{\link{PAMClustering}} (Partioning
Around Medoids). Alternatively, a user-defined function taking \code{xdata}
and \code{Lambda} as arguments and returning a binary and symmetric matrix
for which diagonal elements are equal to zero can be used.}

\item{scale}{logical indicating if the data should be scaled to ensure that
all variables contribute equally to the clustering of the observations.}

\item{resampling}{resampling approach. Possible values are:
\code{"subsampling"} for sampling without replacement of a proportion
\code{tau} of the observations, or \code{"bootstrap"} for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named \code{data} and
\code{tau} and return IDs of observations to be included in the resampled
dataset (see example in \code{\link{Resample}}).}

\item{PFER_method}{method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). With
\code{PFER_method="MB"}, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. With \code{PFER_method="SS"}, the method proposed by Shah
and Samworth (2013) under the assumption of unimodality is used.}

\item{PFER_thr}{threshold in PFER for constrained calibration by error
control. With \code{PFER_thr=Inf} and \code{FDP_thr=Inf}, unconstrained
calibration is used.}

\item{FDP_thr}{threshold in the expected proportion of falsely selected
features (or False Discovery Proportion, FDP) for constrained calibration
by error control. With \code{PFER_thr=Inf} and \code{FDP_thr=Inf},
unconstrained calibration is used.}

\item{n_cores}{number of cores to use for parallel computing. Only available
on Unix systems.}

\item{output_data}{logical indicating if the input datasets \code{xdata} and
\code{ydata} should be included in the output.}

\item{verbose}{logical indicating if a loading bar and messages should be
printed.}

\item{...}{additional parameters passed to the functions provided in
\code{implementation} or \code{resampling}.}
}
\value{
A list with: \item{S}{a matrix of the best (block-specific) stability
  scores for different parameters controlling the number of clusters in the
  underlying algorithm. } \item{Lambda}{a matrix of parameters controlling
  the number of clusters. } \item{Q}{a matrix of average numbers of
  co-members for different parameters controlling the number of clusters.}
  \item{Q_s}{a matrix of calibrated numbers of stable co-members for
  different parameters controlling the number of clusters in the underlying
  algorithm. } \item{P}{a matrix of calibrated thresholds in co-membership
  proportions for different parameters controlling the number of clusters in
  the underlying algorithm. } \item{PFER}{a matrix of the upper-bounds in
  PFER of calibrated consensus clustering models with different (sets of)
  parameters controlling the number of clusters in the underlying algorithm.}
  \item{FDP}{a matrix of the upper-bounds in FDP of calibrated consensus
  clustering models with different parameters controlling the number of
  clusters in the underlying algorithm.} \item{S_2d}{an array of stability
  scores obtained with different combinations of parameters. Columns
  correspond to different thresholds in co-membership proportions. }
  \item{PFER_2d}{an array of computed upper-bounds of PFER obtained with
  different combinations of parameters. Columns correspond to different
  thresholds in co-membership proportions. } \item{FDP_2d}{an array of
  computed upper-bounds of FDP obtained with different combinations of
  parameters. Columns correspond to different thresholds in co-membership
  proportions. } \item{selprop}{an array of co-membership proportions. Rows
  and columns correspond to features being clustered (rows of \code{xdata}).
  Indices along the third dimension correspond to different parameters
  controlling the number of clusters in the underlying algorithm.}
  \item{methods}{a list with \code{type="clustering"}, \code{implementation},
  \code{resampling} and \code{PFER_method} values used for the run.}
  \item{param}{a list with values of other objects used for the run.} For all
  objects except \code{selprop} and those stored in \code{methods} or
  \code{params}, rows correspond to parameter values stored in the output
  \code{Lambda}.
}
\description{
Runs consensus clustering models with different combinations of parameters
controlling the number of clusters in the underlying algorithm and thresholds
in co-membership proportions. These two parameters are jointly calibrated by
maximising the stability score of the model (possibly under a constraint on
the expected number of falsely stably selected features). This function can
be used to identify stable clusters of observations sharing similar profiles.
}
\details{
To ensure reproducibility of the results, the state of the random
  number generator is fixed to \code{seed}. For parallelisation of the code,
  consensus clustering results produced with different \code{seed}s and all
  other parameters equal can be combined (more details in
  \code{\link{Combine}}).
}
\examples{
\dontshow{
set.seed(1)
simul <- SimulateClustering(n = c(5, 5, 5), pk = 10)
stab <- Clustering(
  xdata = simul$data,
  Lambda = 1:3, K = 5,
  verbose = FALSE
)
mymembership <- Clusters(stab)
}
\dontrun{

# Simulation of 15 observations belonging to 3 groups
set.seed(1)
simul <- SimulateClustering(
  n = c(5, 5, 5), pk = 100,
  v_within = c(-1, -0.5), continuous = TRUE
)
par(mar = c(5, 5, 5, 5))
Heatmap(
  mat = cor(t(simul$data)),
  colours = c("navy", "white", "red"),
  legend_range = c(-1, 1)
)

# Consensus clustering based on hierarchical clustering
stab <- Clustering(xdata = simul$data)
CalibrationPlot(stab, xlab = expression(italic(k)))
SelectionProportions(stab)
plot(Graph(Adjacency(stab), satellites = TRUE))
table(simul$theta, Clusters(stab))

# Consensus clustering based on k-means clustering
stab <- Clustering(
  xdata = simul$data,
  implementation = KMeansClustering
)
table(simul$theta, Clusters(stab))

# Consensus clustering based on Gaussian Mixture Models
stab <- Clustering(
  xdata = simul$data,
  implementation = GMMClustering
)
table(simul$theta, Clusters(stab))

# Consensus clustering based on PAM clustering
stab <- Clustering(
  xdata = simul$data,
  implementation = PAMClustering
)
table(simul$theta, Clusters(stab))
}

}
\references{
\insertRef{ourstabilityselection}{focus}

  \insertRef{stabilityselectionMB}{focus}

  \insertRef{stabilityselectionSS}{focus}
}
\seealso{
\code{\link{Resample}}, \code{\link{StabilityScore}},
  \code{\link{HierarchicalClustering}}, \code{\link{KMeansClustering}},
  \code{\link{GMMClustering}}, \code{\link{PAMClustering}}

Other stability selection functions: 
\code{\link{BiSelection}()},
\code{\link{GraphicalModel}()},
\code{\link{VariableSelection}()}
}
\concept{stability selection functions}
